{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, StratifiedKFold, RandomizedSearchCV, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('final_telecom_churn_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = data.drop('Churn', axis=1)\n",
    "outputs = data['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(inputs, outputs, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfolds = 5\n",
    "startified_split = StratifiedKFold(n_splits=kfolds, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [('XGB', XGBClassifier()), ('DT', DecisionTreeClassifier()), ('GB', GradientBoostingClassifier()),\n",
    "         ('LGBM', LGBMClassifier()), ('RF', RandomForestClassifier()), ('SVM', SVC())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB cross validation accuracy score is : 0.7854\n",
      "DT cross validation accuracy score is : 0.7299\n",
      "GB cross validation accuracy score is : 0.7977\n",
      "LGBM cross validation accuracy score is : 0.7888\n",
      "RF cross validation accuracy score is : 0.7883\n",
      "SVM cross validation accuracy score is : 0.7863\n"
     ]
    }
   ],
   "source": [
    "for name, model in models:\n",
    "    cv_result = cross_val_score(model, x_train,y_train, cv=startified_split, scoring='accuracy', n_jobs=-1)\n",
    "    score = round(np.mean(cv_result), 4)\n",
    "    print(f'{name} cross validation accuracy score is : {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient boosting, random forest and Light gradient boosting performing best. <br>\n",
    "due to system limitations we will hypertune only these models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_model = [('GB', GradientBoostingClassifier()), ('LGBM', LGBMClassifier()), ('RF', RandomForestClassifier())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypertuning_params = {\n",
    "    'GB': {\n",
    "        'learning_rate': [0.05],\n",
    "        'n_estimators' : [10, 50, 100, 200, 500],\n",
    "        'max_depth' : [3, 5, 10],\n",
    "        'subsample': [0.7, 0.8, 1]\n",
    "    },\n",
    "    'LGBM': {\n",
    "        'learning_rate': [0.05],\n",
    "        'n_estimators' : [10, 50, 100, 200, 500],\n",
    "        'max_depth' : [3, 5, 10],\n",
    "        'subsample': [0.7, 0.8, 1],\n",
    "        'max_bin ': [200, 250, 300]\n",
    "    },\n",
    "    'RF': {\n",
    "        'max_depth' : [3, 5, 10],\n",
    "        'max_leaf_nodes': [10, 25, 30, None],\n",
    "        'min_samples_leaf': [1, 10, 50, 100],\n",
    "        'n_estimators' : [10, 50, 100, 200, 500],\n",
    "        'bootstrap' : [True, False],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   57.6s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GB\n",
      "Best Parameters {'subsample': 0.8, 'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.05}\n",
      "Best Score 0.8010296280068904\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   11.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM\n",
      "Best Parameters {'subsample': 1, 'n_estimators': 100, 'max_depth': 5, 'max_bin ': 250, 'learning_rate': 0.05}\n",
      "Best Score 0.7990788036583079\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   20.0s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   24.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF\n",
      "Best Parameters {'n_estimators': 50, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'max_depth': 10, 'bootstrap': True}\n",
      "Best Score 0.8010302584235486\n"
     ]
    }
   ],
   "source": [
    "for name, model in selected_model:\n",
    "    randomize_result = RandomizedSearchCV(model, hypertuning_params[name], cv=startified_split, verbose=1, n_jobs=-1)\n",
    "    result = randomize_result.fit(x_train, y_train)\n",
    "    print(name)\n",
    "    print('Best Parameters',result.best_params_)\n",
    "    print('Best Score',result.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's stack all three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(subsample=0.8, n_estimators=200, max_depth=3, learning_rate=0.05)\n",
    "lgbm = LGBMClassifier(subsample=0.8, n_estimators=100, max_depth=5, learning_rate=0.05)\n",
    "rf = RandomForestClassifier(n_estimators=50, min_samples_leaf=10, max_leaf_nodes=None, max_depth=10, bootstrap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=10, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=10, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb.fit(x_train, y_train)\n",
    "lgbm.fit(x_train, y_train)\n",
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(gb, open('gradient_boosting_model.sav', 'wb'))\n",
    "pickle.dump(lgbm, open('light_gradient_boosting.sav', 'wb'))\n",
    "pickle.dump(rf, open('random_forest.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_frequent(List): \n",
    "    return max(set(List), key = List.count)\n",
    "def predict(x):\n",
    "    gb_re = np.round(gb.predict(x))\n",
    "    lgbm_re = np.round(lgbm.predict(x))\n",
    "    rf_re = np.round(rf.predict(x))\n",
    "    final_result = []\n",
    "    for i in range(len(rf_re)):\n",
    "        result = most_frequent([gb_re[i], lgbm_re[i], rf_re[i]])\n",
    "        final_result.append(result)\n",
    "    return np.array(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8126330731014905"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By stacking models accuracy increased by one percent.\n",
    "We would need more data to increase accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
